num_trials <- 10
num_successes <- 1
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials, prob_success, num_successes)
sum(likelihood_distribution$probability)
um_trials <- 10
num_successes <- 0
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials, prob_success, num_successes)
num_trials <- 10
num_successes <- 0
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials = num_trials,num_successes =  num_successes, prob_success = prob_success)
ggplot(data = likelihood_distribution, aes(x = prob_success, y = probability)) +
geom_line() +
scale_y_continuous(name = bquote(paste(L, "(", theta[1], " | ", theta[2] == .(num_trials), ", ", y, ")"))) +
scale_x_continuous(name = bquote(paste("Probability of success (", theta, ")")), breaks = seq(0, 1, 0.1)) +
theme_classic()
num_trials <- 7:100
num_successes <- 7
prob_success <- 0.5 #manipulated variable
likelihood_distribution <- compute_binom_probability_density(num_trials, prob_success, num_successes)
likelihood_distribution <- compute_binom_mass_density(num_trials = num_trials,num_successes =  num_successes, prob_success = prob_success)
ggplot(data = likelihood_distribution, aes(x = prob_success, y = probability)) +
geom_line() +
scale_y_continuous(name = bquote(paste(L, "(", theta[1], " | ", theta[2] == .(num_trials), ", ", y, ")"))) +
scale_x_continuous(name = bquote(paste("Probability of success (", theta, ")")), breaks = seq(0, 1, 0.1)) +
theme_classic()
likelihood_distribution <- compute_binom_mass_density(num_trials = num_trials, num_successes =  num_successes, prob_success = prob_success)
likelihood_distribution
num_trials <- 10
num_successes <- 5
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials = num_trials, num_successes =  num_successes, prob_success = prob_success)
sum(likelihood_distribution$probability)
num_trials <- 10
num_successes <- 0
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials = num_trials, num_successes =  num_successes, prob_success = prob_success)
sum(likelihood_distribution$probability)
num_trials <- 10
num_successes <- 10
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials = num_trials, num_successes =  num_successes, prob_success = prob_success)
sum(likelihood_distribution$probability)
.6*.3
0.18+.09+.09
# Define the observed sequence of flips
x <- c("H", "T", "T", "H", "H", "T", "H", "T", "T", "H")
# Define a range of values for p
p <- seq(0, 1, by=0.01)
# Compute the likelihood function for the observed data
L <- prod(p^sum(x=="H") * (1-p)^sum(x=="T"))
# Compute the constant K
K <- choose(10, 5)
# Compute the probability density function for the observed data
P <- K * p^sum(x=="H") * (1-p)^sum(x=="T")
# Plot the likelihood function and the probability density function
plot(p, L * P, type="l", lty=2, xlab="p", ylab="Likelihood * Density")
lines(p, P, type="l", lwd=2, col="red")
L
# Define a range of values for p
p <- seq(0, 1, by=0.01)
prod(p^sum(x=="H") * (1-p)^sum(x=="T"))
num_trials <- 10
num_successes <- 7
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
compute_binom_mass_density(num_trials, prob_success, num_successes)
likelihood_distribution <- compute_binom_mass_density(num_trials, prob_success, num_successes)
ggplot(data = likelihood_distribution, aes(x = prob_success, y = probability)) +
geom_line() +
scale_y_continuous(name = bquote(paste(L, "(", theta[1], " | ", theta[2] == .(num_trials), ", ", y, ")"))) +
scale_x_continuous(name = bquote(paste("Probability of success (", theta, ")")), breaks = seq(0, 1, 0.1)) +
theme_classic()
likelihood_distribution$probability / prob_distribution$probability
prob_distribution$probabil
prob_distribution$probability
likelihood_distribution$probability
likelihood_distribution$probability[50]
prob_distribution$probability
likelihood_distribution[51]
likelihood_distribution[ ,51]
likelihood_distribution[ ,51]
likelihood_distribution[ ,51]
likelihood_distribution
likelihood_distribution[ 51,]
prob_distribution$probability
num_trials <- 20
num_successes <- 14
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
compute_binom_mass_density(num_trials, prob_success, num_successes)
likelihood_distribution <- compute_binom_mass_density(num_trials, prob_success, num_successes)
likelihood_distribution[ 51,]
prob_distribution$probability
0.03696442/0.1171875000
num_trials <- 30
num_successes <- 21
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
compute_binom_mass_density(num_trials, prob_success, num_successes)
num_trials <- 30
num_successes <- 21
prob_success <- seq(from = 0, to = 1, by = 0.01) #manipulated variable
likelihood_distribution <- compute_binom_mass_density(num_trials, prob_success, num_successes)
likelihood_distribution[ 51,]
prob_distribution$probability
0.01332457/0.1171875000
likelihood_distribution[ 51,]
0.01332457/0.1171875000
0.03696442/0.1171875000
p <- 0.50
likelihood <- p^6 * (1-p)^4
likelihood
p <- seq(from = 0, to = 1.00, by = 0.01)
likelihood <- p^6 * (1-p)^4
likelihood
sum(likelihood)
sum(likelihood)*210
p <- seq(from = 0, to = 1.00, by = 0.001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)
sum(likelihood)*210
p <- seq(from = 0, to = 1.00, by = 0.001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)*0.003968254
p <- seq(from = 0, to = 1.00, by = 0.00001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)*0.003968254
p <- seq(from = 0, to = 1.00, by = 0.0001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)*0.003968254
p <- seq(from = 0, to = 1.00, by = 0.000001)
sum(likelihood)*0.003968254
p <- seq(from = 0, to = 1.00, by = 0.0000001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)*0.003968254
p <- seq(from = 0, to = 1.00, by = 0.000001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)*0.003968254
p <- seq(from = 0, to = 1.00, by = 0.00001)
likelihood <- p^6 * (1-p)^4
sum(likelihood)*0.003968254
#load packages
library(easypackages)
packages <- c('devtools','tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'shiny',
'knitr', 'RefManageR', 'gluedown', 'formatR', 'reticulate')
libraries(packages)
knitr::opts_chunk$set(comment = NA, echo = TRUE, eval = TRUE, warning = FALSE)
# knitr hook to use Hugo highlighting options
knitr::knit_hooks$set(
source = function(x, options) {
hlopts <- options$hlopts
paste0(
"```", "r ",
if (!is.null(hlopts)) {
paste0("{",
glue::glue_collapse(
glue::glue('{names(hlopts)}={hlopts}'),
sep = ","
), "}"
)
},
"\n", glue::glue_collapse(x, sep = "\n"), "\n```\n"
)
}
)
chunk_class <- function(before, options, envir) {
class_name = options$class_name
if (!is.null(before)) {
lines <- unlist(strsplit(x = before, split = "\n")) #separate lines of code at \n
n <- length(lines)  #determines numbers of lines
#if (line_numbers) {
res <- paste0("<pre><code class='", class_name, "'>", before, "</code></pre>")
#paste0("<pre><code class='", class_name, "'>", before, "</code></pre>")
#}
#res <- paste0("<pre>", paste0("<span class='line-number'>", 1:n,
#"</span><code class ='", class_name, "'>", lines, "</code>"), "</pre>")
}
return(res)
}
knitr::knit_hooks$set(output = chunk_class, preserve = TRUE)
#knitr::knit_hooks$set(output = function(x, options) {
#  paste(c("<pre><code class = 'r-code'>",
#        gsub('^## Error', '**Error**', x),
#        '</pre></code>'), collapse = '\n')
#})
options(reticulate.autocomplete = TRUE)
#install_miniconda(path = "e:/miniconda", update = T)
use_condaenv(condaenv = "r-reticulate", conda = "/Users/sebastiansciarra/Library/r-miniconda/bin/conda")
#py_packages <- c('numpy', 'pandas', 'scipy')
#py_install(packages = py_packages)
reticulate::repl_python()
#install_miniconda(path = "e:/miniconda", update = T)
use_condaenv(condaenv = "r-reticulate", conda = "/Users/sebastiansciarra/Library/r-miniconda/bin/conda")
#install_miniconda(path = "e:/miniconda", update = T)
use_condaenv(condaenv = "r-reticulate", conda = "/Users/sebastiansciarra/Library/r-miniconda/bin/conda")
reticulate::repl_python()
incomplete_data_like <- py$incomplete_data_like
lower_bound <- py$lower_bound_df
lower_bound_2 <- py$lower_bound_df_2
ggplot(data = incomplete_data_like, mapping = aes(x = p1, y = likelihood)) +
geom_line(linewidth = 1) +
geom_line(inherit.aes = F, data = lower_bound, mapping = aes(x = p1, y = likelihood), linewidth = 0.5) +
geom_line(inherit.aes = F, data = lower_bound_2, mapping = aes(x = p1, y = likelihood), linewidth = 0.5) +
scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1)) +
theme_classic(base_family = 'Helvetica')
reticulate::repl_python()
?conda_create
#create and use conda environment
#conda_create(envname = 'blog_posts',  python_version = '3.10.11')
use_condaenv(condaenv = 'blog_posts')
#install packages in conda environment
py_packages <- c('numpy', 'pandas', 'scipy')
conda_install(envname = 'blog_posts', packages = py_packages)
conda_list()
#create and use conda environment
#conda_create(envname = 'blog_posts',  python_version = '3.10.11')
use_condaenv(condaenv = 'blog_posts')
conda_list(conda = 'blog_posts')
py_list_packages(envname = 'blog_posts')
#
py_list_packages(envname = 'blog_posts', type = 'conda')
#load packages
library(easypackages)
packages <- c('devtools','tidyverse', 'reticulate', 'RColorBrewer')
libraries(packages)
knitr::opts_chunk$set(comment = NA, echo = TRUE, eval = TRUE, warning = FALSE)
# knitr hook to use Hugo highlighting options
knitr::knit_hooks$set(
source = function(x, options) {
hlopts <- options$hlopts
paste0(
"```", "r ",
if (!is.null(hlopts)) {
paste0("{",
glue::glue_collapse(
glue::glue('{names(hlopts)}={hlopts}'),
sep = ","
), "}"
)
},
"\n", glue::glue_collapse(x, sep = "\n"), "\n```\n"
)
}
)
chunk_class <- function(before, options, envir) {
class_name = options$class_name
if (!is.null(before)) {
lines <- unlist(strsplit(x = before, split = "\n")) #separate lines of code at \n
n <- length(lines)  #determines numbers of lines
#if (line_numbers) {
res <- paste0("<pre><code class='", class_name, "'>", before, "</code></pre>")
#paste0("<pre><code class='", class_name, "'>", before, "</code></pre>")
#}
#res <- paste0("<pre>", paste0("<span class='line-number'>", 1:n,
#"</span><code class ='", class_name, "'>", lines, "</code>"), "</pre>")
}
return(res)
}
knitr::knit_hooks$set(output = chunk_class, preserve = TRUE)
#knitr::knit_hooks$set(output = function(x, options) {
#  paste(c("<pre><code class = 'r-code'>",
#        gsub('^## Error', '**Error**', x),
#        '</pre></code>'), collapse = '\n')
#})
#use_virtualenv("EM_post")
options(reticulate.autocomplete = TRUE)
#create and use conda environment
#conda_create(envname = 'blog_posts',  python_version = '3.10.11')
use_condaenv(condaenv = 'blog_posts')
#install packages in conda environment
#py_packages <- c('numpy', 'pandas', 'scipy')
#conda_install(envname = 'blog_posts', packages = py_packages)
#useful for checking what packages are loaded
#py_list_packages(envname = 'blog_posts', type = 'conda')
reticulate::repl_python()
#install packages in conda environment
py_packages <- c('numpy', 'pandas', 'scipy', 'functools')
conda_install(envname = 'blog_posts', packages = py_packages)
#install packages in conda environment
py_packages <- c('numpy', 'pandas', 'scipy', 'reduce')
conda_install(envname = 'blog_posts', packages = py_packages)
conda_install(envname = 'blog_posts', packages = 'functools')
#load packages
library(easypackages)
packages <- c('devtools','tidyverse', 'reticulate', 'RColorBrewer')
libraries(packages)
knitr::opts_chunk$set(comment = NA, echo = TRUE, eval = TRUE, warning = FALSE)
# knitr hook to use Hugo highlighting options
knitr::knit_hooks$set(
source = function(x, options) {
hlopts <- options$hlopts
paste0(
"```", "r ",
if (!is.null(hlopts)) {
paste0("{",
glue::glue_collapse(
glue::glue('{names(hlopts)}={hlopts}'),
sep = ","
), "}"
)
},
"\n", glue::glue_collapse(x, sep = "\n"), "\n```\n"
)
}
)
chunk_class <- function(before, options, envir) {
class_name = options$class_name
if (!is.null(before)) {
lines <- unlist(strsplit(x = before, split = "\n")) #separate lines of code at \n
n <- length(lines)  #determines numbers of lines
#if (line_numbers) {
res <- paste0("<pre><code class='", class_name, "'>", before, "</code></pre>")
#paste0("<pre><code class='", class_name, "'>", before, "</code></pre>")
#}
#res <- paste0("<pre>", paste0("<span class='line-number'>", 1:n,
#"</span><code class ='", class_name, "'>", lines, "</code>"), "</pre>")
}
return(res)
}
knitr::knit_hooks$set(output = chunk_class, preserve = TRUE)
#knitr::knit_hooks$set(output = function(x, options) {
#  paste(c("<pre><code class = 'r-code'>",
#        gsub('^## Error', '**Error**', x),
#        '</pre></code>'), collapse = '\n')
#})
#use_virtualenv("EM_post")
options(reticulate.autocomplete = TRUE)
#create and use conda environment
#conda_create(envname = 'blog_posts',  python_version = '3.10.11')
use_condaenv(condaenv = 'blog_posts')
#install packages in conda environment
#py_packages <- c('numpy', 'pandas', 'scipy')
#conda_install(envname = 'blog_posts', packages = py_packages)
#useful for checking what packages are loaded
#py_list_packages(envname = 'blog_posts', type = 'conda')
reticulate::repl_python()
library(kableExtra)
#import dataframes from Python
heads_df <- round(x = py$eff_number_heads, digits = 1)
tails_df <- round(x = py$eff_number_tails, digits = 1)
#join dataframes and include additional information that is contained in figure table
effective_number_data <- data.frame('Coin A' = paste0("$\\approx$ ", heads_df$coin_A, " H, ", tails_df$coin_A, " T"),
'Coin B' = paste0("$\\approx$ ", heads_df$coin_B, " H, ", tails_df$coin_B, " T"),
check.names = F)
library(kableExtra)
#import dataframes from Python
heads_df <- round(x = py$eff_number_heads, digits = 1)
tails_df <- round(x = py$eff_number_tails, digits = 1)
#join dataframes and include additional information that is contained in figure table
effective_number_data <- data.frame(
'Coin A' = paste0("$\\approx$ ", heads_df$coin_A, " H, ", tails_df$coin_A, " T"),
'Coin B' = paste0("$\\approx$ ", heads_df$coin_B, " H, ", tails_df$coin_B, " T"),
check.names = F)
#alternate row colouring
first_col_colours <- rep(x = c('#E8C3BE', '#F6E5E2'), length.out = nrow(effective_number_data) )
second_col_colours <- rep(x = c('#C7D7E0', '#E5ECF0'), length.out = nrow(effective_number_data))
kbl(x = effective_number_data, format = 'html', digits = 2, booktabs = TRUE,
align = c('c', 'c'), escape = F,
caption = 'Effective Number of Heads and Tails for Each of Two Coins',
#CSS styling
##make all borders white
table.attr = 'style="border-bottom: 1pt solid white"') %>%
##replace header bottom border with white one
row_spec(row = 0, extra_css = 'border-bottom: 1pt solid white; color: white ', bold= F)  %>%
#row colouring
column_spec(width = '4cm', column = 1, color = '#8F4944', background = first_col_colours) %>%
column_spec(width = '4cm',column = 2, color = '#476685', background = second_col_colours) %>%
#place after so that white colour overrides previous colours
row_spec(row = nrow(effective_number_data), background = 'white') %>%
#increase row heights
#footnote
footnote(general =  "<em>Note</em>. Table was recreated to resemble the table in Step 3 of Figure \\ref{fig:do-batzoglou}.",  threeparttable = T,  escape = F, general_title = ' ') %>%
#give table class name so that above CSS code is applied on it
kable_styling(htmltable_class = 'do_batzoglou_table', position = 'center', html_font = 'Arial')
reticulate::repl_python()
#devtools::install_github("nicolash2/ggbrace")
library(latex2exp)
library(ggbrace)
incomplete_data_like <- py$incomplete_data_like
old_lower_bound <- py$old_lower_bound
new_lower_bound <- py$new_lower_bound
#combine old and new lower bounds data sets and introduce factor variable to track old/new status
lower_bounds_df <- bind_rows(
data.frame(old_lower_bound, iteration = "old"),
data.frame(new_lower_bound, iteration = "new")) %>%
mutate(iteration = as.factor(iteration))
#Three components for making EM algorithm plot
#1)Vertical dashed line data that shows intersection points
##old lower bound and value where it intersects incomplete-data log-likelihood
old_p_value <- py$p[1]
old_intersection <- py$compute_lower_bound(responsibilities = py$rs_old,
mu = py$mu_fixed,
p = c(old_p_value, 0.1))
#devtools::install_github("nicolash2/ggbrace")
library(latex2exp)
library(ggbrace)
incomplete_data_like <- py$incomplete_data_like
old_lower_bound <- py$old_lower_bound
new_lower_bound <- py$new_lower_bound
#combine old and new lower bounds data sets and introduce factor variable to track old/new status
lower_bounds_df <- bind_rows(
data.frame(old_lower_bound, iteration = "old"),
data.frame(new_lower_bound, iteration = "new")) %>%
mutate(iteration = as.factor(iteration))
#Three components for making EM algorithm plot
#1)Vertical dashed line data that shows intersection points
##old lower bound and value where it intersects incomplete-data log-likelihood
old_p_value <- py$p[1]
old_intersection <- py$compute_lower_bound(responsibilities = py$old_responsibilities,
mu = py$mu_fixed,
p = c(old_p_value, 0.1))
##old lower bound and value where it intersects incomplete-data log-likelihood
new_p_value <- py$estimates$p_new[1]
##old lower bound and value where it intersects incomplete-data log-likelihood
new_p_value <- py$estimates[1]
new_intersection <- py$compute_lower_bound(responsibilities = py$new_responsibilities,
mu = py$mu_fixed,
p = c(new_p_value, 0.1))
##vertical line data set
intersection_data <- data.frame('p1_value' = c(old_p_value, new_p_value),
'y_min' = c(-20, -20),
'intersection_point' = c(old_intersection, new_intersection))
#devtools::install_github("nicolash2/ggbrace")
library(latex2exp)
library(ggbrace)
incomplete_data_like <- py$incomplete_data_like
old_lower_bound <- py$old_lower_bound
new_lower_bound <- py$new_lower_bound
#combine old and new lower bounds data sets and introduce factor variable to track old/new status
lower_bounds_df <- bind_rows(
data.frame(old_lower_bound, iteration = "old"),
data.frame(new_lower_bound, iteration = "new")) %>%
mutate(iteration = as.factor(iteration))
#Three components for making EM algorithm plot
#1)Vertical dashed line data that shows intersection points
##old lower bound and value where it intersects incomplete-data log-likelihood
old_p_value <- py$p[1]
old_intersection <- py$compute_lower_bound(responsibilities = py$old_responsibilities,
mu = py$mu_fixed,
p = c(old_p_value, 0.1))
##old lower bound and value where it intersects incomplete-data log-likelihood
new_p_value <- py$estimates[1]
new_intersection <- py$compute_lower_bound(responsibilities = py$new_responsibilities,
mu = py$mu_fixed,
p = c(new_p_value, 0.1))
##vertical line data set
intersection_data <- data.frame('p1_value' = c(old_p_value, new_p_value),
'y_min' = c(-20, -20),
'intersection_point' = c(old_intersection, new_intersection))
#2) X-axis labels to show the new and old parameter values
x_axis_labels <- sprintf("%0.2f", seq(from = 0, to = 1, by = 0.1))
##modify second and fifth elements to include theta labels
x_axis_labels[2] <- expression(atop("0.10", p^old))
x_axis_labels[5] <- expression(atop("0.40", p^new))
#3) Math text data to show mathematical notation
##create latex math to be shown on the plot
incomplete_data_log <- "$L(\\textit{p}_1|\\textbf{x})$"
lbound_new <- "\u2112$(\\textit{P}(\\textbf{z}, \\textbf{x}|\\textit{p^{new}}), \\textit{p_1})$"
lbound_old <- "\u2112$(\\textit{P}(\\textbf{z}, \\textbf{x}|\\textit{p^{old}}), \\textit{p_1})$"
##create data frame
math_text_data <- data.frame('latex_math' = c(incomplete_data_log, lbound_new, lbound_old),
'x' = c(0.95, 0.95, 0.85),
'y' = c(-6.5, -8.2, -13.5))
#4) Brace data information for KL divergence and increase in lower bound
kl_divergence <- "$KL(\\textit{P}(\\textbf{z}, \\textbf{x}|\\textit{p^{new}})\\|\\textit{P}(\\textbf{z}, \\textbf{x}|\\textit{p^{old}}))$"
lbound_increase <- "$\\textit{Q}(\\textit{p}^{new}|\\textit{p}^{old}) -\\textit{Q}(\\textit{p}^{old}|\\textit{p}^{old})$"
max_old_lbound <- old_lower_bound$likelihood[which.max(old_lower_bound$likelihood)]
em_plot <- ggplot(data = incomplete_data_like, mapping = aes(x = p1, y = likelihood)) +
#vertical dashed lines
geom_segment(data = intersection_data,
mapping = aes(x = p1_value, y = y_min, xend = p1_value, yend = intersection_point),
linetype = 2) +
#curly brace for KL divergence
geom_brace(aes(x = c(0.4, 0.45), y = c(max_old_lbound, new_intersection),
label=TeX(kl_divergence, output="character")),
inherit.data=F, labelsize=4, rotate = 90, parse=T) +
#curly brace for increase in evidence lower bound
geom_brace(aes(x = c(0.4, 0.45), y = c(old_intersection, max_old_lbound),
label=TeX(lbound_increase, output="character")),
inherit.data=F, labelsize=4, rotate = 90, parse=T, mid = 0.25) +
#likelihoods
geom_line(linewidth = 1) +
geom_line(inherit.aes = F, data = lower_bounds_df,
mapping = aes(x = p1, y = likelihood, group = iteration, color = iteration),
linewidth = 0.5) +
#colour details
scale_color_manual(values = c('old' ='#9ECAE1', 'new' =  '#2171B5')) +
#math text
geom_text(inherit.aes = F, data = math_text_data, parse = TRUE, size = 4,
mapping = aes(x = x, y = y, label=TeX(latex_math, output="character"))) +
#axis & legend details
scale_x_continuous(name = expression(Coin~1~Probability~of~Heads(italic(p)[1]*';'~italic(p)[2]~'= 0.10')),
breaks = seq(from = 0, to = 1, by = 0.1),
limits = c(0, 1.1),
labels = x_axis_labels) +
scale_y_continuous(name = 'Log-Likelihood',
limits = c(-20, -5),
expand = c(0, 0)) +
labs(color = 'Lower bound') +
#other aesthetics
theme_classic(base_family = 'Helvetica', base_size = 14) +
theme(text = element_text(color = "#002241"),
axis.line = element_line(color = "#002241"),
axis.ticks = element_line(color =  "#002241"),
axis.text = element_text(color = "#002241"))
#high resolution needed for greek letter to print clearly
ggsave(filename = 'images/em_plot.png', plot = em_plot, width = 10, height = 6, dpi = 1000)
py$p[1]
py$p
estimates
py$estimates
reticulate::repl_python()
